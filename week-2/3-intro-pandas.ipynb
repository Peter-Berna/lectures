{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaptive-irrigation",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Installation\" data-toc-modified-id=\"Installation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Installation</a></span></li><li><span><a href=\"#Introduction-to-pandas-data-structures\" data-toc-modified-id=\"Introduction-to-pandas-data-structures-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Introduction to pandas data structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Series\" data-toc-modified-id=\"Series-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Series</a></span></li><li><span><a href=\"#Find-NaN-values\" data-toc-modified-id=\"Find-NaN-values-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Find NaN values</a></span></li></ul></li><li><span><a href=\"#Read/write-data\" data-toc-modified-id=\"Read/write-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Read/write data</a></span><ul class=\"toc-item\"><li><span><a href=\"#We-load-data-in-CSV-format\" data-toc-modified-id=\"We-load-data-in-CSV-format-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>We load data in CSV format</a></span></li><li><span><a href=\"#We-load-data-in-xlsx-format\" data-toc-modified-id=\"We-load-data-in-xlsx-format-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>We load data in xlsx format</a></span></li><li><span><a href=\"#We-display-the-first-rows\" data-toc-modified-id=\"We-display-the-first-rows-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>We display the first rows</a></span></li><li><span><a href=\"#We-display-the-last-rows\" data-toc-modified-id=\"We-display-the-last-rows-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>We display the last rows</a></span></li><li><span><a href=\"#Visualize-a-random-sample\" data-toc-modified-id=\"Visualize-a-random-sample-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Visualize a random sample</a></span></li></ul></li><li><span><a href=\"#Exploratory-analysis-of-a-dataframe\" data-toc-modified-id=\"Exploratory-analysis-of-a-dataframe-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exploratory analysis of a dataframe</a></span></li><li><span><a href=\"#Basic-operations-with-dataframes\" data-toc-modified-id=\"Basic-operations-with-dataframes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Basic operations with dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#We-select-a-column\" data-toc-modified-id=\"We-select-a-column-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>We select a column</a></span></li><li><span><a href=\"#We-select-several-columns\" data-toc-modified-id=\"We-select-several-columns-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>We select several columns</a></span></li><li><span><a href=\"#Get-the-unique-values-​​of-a-column-(ie-a-Series)\" data-toc-modified-id=\"Get-the-unique-values-​​of-a-column-(ie-a-Series)-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Get the unique values ​​of a column (ie a Series)</a></span></li><li><span><a href=\"#Change-the-data-type-of-a-column\" data-toc-modified-id=\"Change-the-data-type-of-a-column-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Change the data type of a column</a></span></li><li><span><a href=\"#We-filter-the-data-by-the-value-of-the-columns\" data-toc-modified-id=\"We-filter-the-data-by-the-value-of-the-columns-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>We filter the data by the value of the columns</a></span></li><li><span><a href=\"#Copy-a-dataframe-and-rename-columns\" data-toc-modified-id=\"Copy-a-dataframe-and-rename-columns-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Copy a dataframe and rename columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Rename-columns\" data-toc-modified-id=\"Rename-columns-6.6.1\"><span class=\"toc-item-num\">6.6.1&nbsp;&nbsp;</span>Rename columns</a></span></li><li><span><a href=\"#We-can-rename-the-columns-by-crushing-the-instance-attribute...-does-this-ring-a-bell?\" data-toc-modified-id=\"We-can-rename-the-columns-by-crushing-the-instance-attribute...-does-this-ring-a-bell?-6.6.2\"><span class=\"toc-item-num\">6.6.2&nbsp;&nbsp;</span>We can rename the columns by crushing the instance attribute... does this ring a bell?</a></span></li></ul></li><li><span><a href=\"#delete-columns\" data-toc-modified-id=\"delete-columns-6.7\"><span class=\"toc-item-num\">6.7&nbsp;&nbsp;</span>delete columns</a></span></li><li><span><a href=\"#delete-rows\" data-toc-modified-id=\"delete-rows-6.8\"><span class=\"toc-item-num\">6.8&nbsp;&nbsp;</span>delete rows</a></span></li><li><span><a href=\"#Reset_index-and-set_index\" data-toc-modified-id=\"Reset_index-and-set_index-6.9\"><span class=\"toc-item-num\">6.9&nbsp;&nbsp;</span>Reset_index and set_index</a></span><ul class=\"toc-item\"><li><span><a href=\"#SET_INDEX\" data-toc-modified-id=\"SET_INDEX-6.9.1\"><span class=\"toc-item-num\">6.9.1&nbsp;&nbsp;</span>SET_INDEX</a></span></li></ul></li><li><span><a href=\"#Operations-between-columns\" data-toc-modified-id=\"Operations-between-columns-6.10\"><span class=\"toc-item-num\">6.10&nbsp;&nbsp;</span>Operations between columns</a></span></li></ul></li><li><span><a href=\"#Apply-!\" data-toc-modified-id=\"Apply-!-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Apply !</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Passing-a-map-or-an-apply\" data-toc-modified-id=\"Passing-a-map-or-an-apply-7.0.1\"><span class=\"toc-item-num\">7.0.1&nbsp;&nbsp;</span>Passing a map or an apply</a></span></li><li><span><a href=\"#Receive:\" data-toc-modified-id=\"Receive:-7.0.2\"><span class=\"toc-item-num\">7.0.2&nbsp;&nbsp;</span>Receive:</a></span></li></ul></li></ul></li><li><span><a href=\"#Df-.loc-&amp;-.iloc\" data-toc-modified-id=\"Df-.loc-&amp;-.iloc-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Df .loc &amp; .iloc</a></span><ul class=\"toc-item\"><li><span><a href=\"#Select-rows-and-columns-in-Pandas-by-position-with-iloc\" data-toc-modified-id=\"Select-rows-and-columns-in-Pandas-by-position-with-iloc-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Select rows and columns in Pandas by position with iloc</a></span></li><li><span><a href=\"#Select-rows-and-columns-in-Pandas-based-on-labels-with-loc\" data-toc-modified-id=\"Select-rows-and-columns-in-Pandas-based-on-labels-with-loc-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Select rows and columns in Pandas based on labels with loc</a></span><ul class=\"toc-item\"><li><span><a href=\"#Based-on-label\" data-toc-modified-id=\"Based-on-label-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span>Based on label</a></span></li></ul></li></ul></li><li><span><a href=\"#Order-a-dataframe\" data-toc-modified-id=\"Order-a-dataframe-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Order a dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Look-for-null-values\" data-toc-modified-id=\"Look-for-null-values-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Look for null values</a></span><ul class=\"toc-item\"><li><span><a href=\"#It-is-null?\" data-toc-modified-id=\"It-is-null?-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>It is null?</a></span></li><li><span><a href=\"#Is-NOT-null?\" data-toc-modified-id=\"Is-NOT-null?-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>Is NOT null?</a></span></li><li><span><a href=\"#Sum-the-null-values-​​of-each-column\" data-toc-modified-id=\"Sum-the-null-values-​​of-each-column-9.1.3\"><span class=\"toc-item-num\">9.1.3&nbsp;&nbsp;</span>Sum the null values ​​of each column</a></span></li></ul></li><li><span><a href=\"#delete-null-values\" data-toc-modified-id=\"delete-null-values-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>delete null values</a></span></li><li><span><a href=\"#How-to-fill-in-the-missing-data\" data-toc-modified-id=\"How-to-fill-in-the-missing-data-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>How to fill in the missing data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#CATEGORIES-IN-DATAFRAME:-DOCUMENTATION\" data-toc-modified-id=\"CATEGORIES-IN-DATAFRAME:-DOCUMENTATION-9.3.0.1\"><span class=\"toc-item-num\">9.3.0.1&nbsp;&nbsp;</span>CATEGORIES IN DATAFRAME: DOCUMENTATION</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#We-delete-the-duplicates\" data-toc-modified-id=\"We-delete-the-duplicates-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>We delete the duplicates</a></span></li><li><span><a href=\"#Data-aggregation\" data-toc-modified-id=\"Data-aggregation-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Data aggregation</a></span><ul class=\"toc-item\"><li><span><a href=\"#GroupBy\" data-toc-modified-id=\"GroupBy-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>GroupBy</a></span><ul class=\"toc-item\"><li><span><a href=\"#You-may-ask,-what-if-I-want-to-group-by-more-columns?\" data-toc-modified-id=\"You-may-ask,-what-if-I-want-to-group-by-more-columns?-11.1.1\"><span class=\"toc-item-num\">11.1.1&nbsp;&nbsp;</span>You may ask, what if I want to group by more columns?</a></span></li></ul></li><li><span><a href=\"#Union-of-Dataframes\" data-toc-modified-id=\"Union-of-Dataframes-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Union of Dataframes</a></span></li><li><span><a href=\"#Concat\" data-toc-modified-id=\"Concat-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Concat</a></span></li><li><span><a href=\"#Merge\" data-toc-modified-id=\"Merge-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;</span>Merge</a></span></li><li><span><a href=\"#Join\" data-toc-modified-id=\"Join-11.5\"><span class=\"toc-item-num\">11.5&nbsp;&nbsp;</span>Join</a></span></li></ul></li><li><span><a href=\"#Export-data\" data-toc-modified-id=\"Export-data-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Export data</a></span></li><li><span><a href=\"#Pandas-usual-methods\" data-toc-modified-id=\"Pandas-usual-methods-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Pandas usual methods</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Further-materials\" data-toc-modified-id=\"Further-materials-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Further materials</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-academy",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-needle",
   "metadata": {},
   "source": [
    "![pandas](https://media.giphy.com/media/nVsLCrW5iHf6E/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751721df",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Introduction\n",
    "Pandas is undoubtedly the most widely used library in the Python ecosystem for data manipulation and analysis. It's fast, powerful, flexible, easy to use and open source.\n",
    "\n",
    "\n",
    "Among its main features:\n",
    "\n",
    "- A fast and efficient **DataFrame** object for data manipulation with built-in indexing* \n",
    "\n",
    "- **Reading and writing** of data in many formats: Microsoft Excel, CSV, SQL databases, etc;\n",
    "\n",
    "- Integrated and efficient methods for all types of data manipulation: missing data, subset, union, merge, etc;\n",
    "\n",
    "- Ease of working with temporary data (in fact, Pandas is named after \"PANnel DAta\")\n",
    "\n",
    "- Good **integration with other data analysis or Machine learning libraries**: scikit-learn, scipy, seaborn, plotly, etc;\n",
    "\n",
    "- It is **widely used** in both the private and academic sectors\n",
    "\n",
    "\n",
    "Pandas provides high-level data structures and functions designed to make working with structured or tabular data fast, easy, and expressive. Since its introduction in 2010, it has helped make Python a powerful and productive data analysis environment. The main pandas objects that will be used in this book are the DataFrame, a column-oriented tabular data structure with row and column labels, and the Series, a labeled one-dimensional array object.\n",
    "\n",
    "Pandas combines the high performance ideas of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases (such as SQL). It provides sophisticated indexing functionality to make it easy to reshape, slice and dice, perform aggregations, and select subsets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-nutrition",
   "metadata": {},
   "source": [
    "![image](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Source: [Forbes](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#1ba071616f63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6680d33",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0e351",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The first thing you should do will always be\n",
    "`pip install pandas`, `conda install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d4f4b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Introduction to pandas data structures\n",
    "To get started with pandas, you'll need to get comfortable with its two working data structures: Series and DataFrame. Although they are not a universal solution to all problems, they provide a solid and easy-to-use foundation for most applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d636439c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Series\n",
    "A Serie is a one-dimensional array object containing a sequence of values ​​(of NumPy-like types) and an associated array of data labels, called its index. The simplest Series is formed from a single array of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_serie = pd.Series([1, 2, 3, \"a string\", 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1570d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(my_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cb5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(my_serie.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(my_serie.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8006ecb",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The string representation of a Series displayed interactively shows the index on the left and the values ​​on the right. Since we didn't specify an index for the data, a default one consisting of the integers 0 to N - 1 (where N is the length of the data) is created. You can get the array representation and the index object of the Series through its values ​​and index attributes, respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f739f4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Another way to think of a Series is as a fixed-length ordered dict, since it is a mapping of index values ​​to data values. It can be used in many contexts where a dictionary could be used.\n",
    "If you have data contained in a Python dict, you can create a Series from it by passing the dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata = {\n",
    "    \"Ohio\": 3000,\n",
    "    \"Texas\": 3030,\n",
    "    \"Oregon\":34343,\n",
    "    \"Utah\":4949,\n",
    "    \"Something else\": 223\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e15554",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series = pd.Series(somedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ede87",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "When only one dict is passed, the resulting String index will have the keys of the dict in order. You can override this by passing the keys of the dict in the order you want them to appear in the resulting String:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"California\", \"Ohio\", \"Oregon\", \"Texas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series = pd.Series(somedata, index=states)\n",
    "somedata_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbefc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Series ():\n",
    "    #def __init__ (self, data, index=None):\n",
    "        #pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a97ba9",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Here, the three values ​​found in sdata were placed in the appropriate places, but since no value was found for 'California', it appears as NaN (not a number), which is considered in pandas to mark missing values ​​or NA. Since \"Utah\" was not included in the states, it is excluded from the resulting object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series[\"Ohio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(somedata_series[\"Ohio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "somedata_series[\"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(somedata_series[\"California\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot do operation with type float -> is there some NaN in that column/row?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7446f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Find NaN values\n",
    "NaN stands for Not A Number and is one of the common ways to represent the missing value in the data. It is a special floating point value and cannot be converted to a type other than float.\n",
    "The NaN value is one of the main problems in data analysis. It is very essential to deal with NaN to get the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(somedata_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a58a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(somedata_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97822f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(somedata_series).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686773c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Read/write data\n",
    "\n",
    "Pandas can read and write data from a wide variety of formats. [Read the documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)\n",
    "Although one of the most common is from a dict of lists of equal length or NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10653d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be mindful of case sensitivity when instantiating pandas objects\n",
    "df = pd.dataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "        'pop': [1.5, 1.7, None, 2.4, 2.9, np.nan]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0622ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef077da",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "If I create a dataframe through a list of dictionaries:\n",
    "- Each dictionary will be a row\n",
    "- The keys will be the names of the columns\n",
    "- They have to have the same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data, orient=\"Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52162b19",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Since we are using Jupyter Notebook, pandas DataFrame objects will be displayed as a more browser-friendly HTML table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4418c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = [\n",
    "    {\"name\":\"clara\",\n",
    "    \"age\": 30},\n",
    "    \n",
    "    {\"name\":\"pau\",\n",
    "    \"age\":19},\n",
    "    \n",
    "    {\"name\":\"albert\",\n",
    "    \"age\":30}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbaae69",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We load data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/avocado_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63239a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40de887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cf09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f682d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_dataset = df.sample(frac=0.15)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ebfa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8754cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ea6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape returns the number of columns and rows into a tuple\n",
    "# Accessing shape is faster than running the method count, as it's an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de81835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = comma separated values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e789df5",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We load data in xlsx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retail = pd.read_excel(\"../datasets/Online Retail.xlsx\")\n",
    "#retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7886577",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We display the first rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6520b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "By default head shows me the first 5 rows, I can see some more or less by passing a number as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387332c9",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We display the last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11134b1f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Exactly the same as with .head() we pass a parameter to .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ca5cd",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Visualize a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7fbf8",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Exploratory analysis of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-release",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ce9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3ba5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe() #statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1695d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[0.10,0.50,0.95]) #statistics defining percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf6d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4e4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aed471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26b6d0",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Basic operations with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Bags'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a42596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b3a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.AveragePrice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.type.value_counts() #type is the name of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total Bags\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b361",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We select a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f62aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"columm\"]\n",
    "df.Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe5788",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We select several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Date\", \"Total Bags\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = list(df.columns)[6:]\n",
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_variable = df[new_list].head()\n",
    "new_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfdd8ef",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Get the unique values ​​of a column (ie a Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d8fa0",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Change the data type of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ff5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AveragePrice\"] # The type is float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AveragePrice\"].astype(dtype=\"int8\") #This reduces in size and also \n",
    "df[\"AveragePrice\"] #truncates the decimals\n",
    "\n",
    "# I need to save it, otherwise it won't be changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc0a80",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We filter the data by the value of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-genre",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58030ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df[\"region\"] !=\"Boston\"] #Whole DF where condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4434d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"region\"] ==\"Boston\") & (df.AveragePrice < 1)] #AveragePrice >= 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4056e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df[\"region\"] ==\"Boston\") & ((df.AveragePrice < 1) | (df[\"Total Bags\"] < 1000))] #AveragePrice >= 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750659e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[((df[\"region\"] ==\"Boston\") | (df[\"region\"] ==\"Albany\")) & (df[\"AveragePrice\"] < 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848ff40",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Copy a dataframe and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_copy = df.copy()\n",
    "my_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5e1955",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Rename columns\n",
    "To rename columns we need a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns = list(df.columns)\n",
    "my_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d979702",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns_changed = {column: column.lower().strip().replace(\" \", \"_\").replace(\":\",\"\") for column in my_columns}\n",
    "my_columns_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d7f8be",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The rename method allows me to rename only the columns that I want, the ones that are in the dictionary. No need to rename all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = my_columns_changed, inplace=True)\n",
    "df.sample()\n",
    "\n",
    "# inplace=True will make sure that I save those changes without the need to save it \n",
    "# into a new variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e809626d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### We can rename the columns by crushing the instance attribute... does this ring a bell?\n",
    "Requires a list with the same number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3027e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns_2 = [i.upper() for i in my_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = my_columns_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ab27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_change = {\n",
    "    \"DATE\":\"dates\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56164158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=minor_change, inplace=True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be832e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"4046\", \"4770\"], axis=1, inplace=True) #Inplace = will save those changes\n",
    "#into the version you're working with\n",
    "#It will save you from saving into another variable\n",
    "#Either inplace=True OR save changes into new_df\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop([\"YEAR\", \"TYPE\"], axis=1) #Inplace = will save those changes\n",
    "new_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"4225\"], axis=1) # No inplace & no new_df\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd90ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"AVERAGEPRICE\", \"TOTAL VOLUME\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b16d6",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### delete rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-complaint",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cae297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([6, 7], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17581dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"path\")\n",
    "#df.read_csv(\"path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017482de",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Rows can also be deleted. Note that the indexes are not reset. The index is associated with the row, not the order.\n",
    "Can the index be restarted? Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b9901",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Reset_index and set_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5ca1d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "We read the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html) to understand some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-holly",
   "metadata": {},
   "source": [
    "#### SET_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-record",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e33381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True) #drop=True will prevent the index to be appended into the DF\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"index\"], axis=1, inplace=True) #this works\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f906ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ea3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df.set_index(\"dates\")\n",
    "df_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41774c2",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "What can we use to have the date as an index?\n",
    "We will see it later, to analyze temporary series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={'figure.figsize': (20.,6.)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42663b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba579c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_dates, x=df_dates.index, y=df[\"AVERAGEPRICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776cc6d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Operations between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can create new columns just by assigning a name\n",
    "df[\"small_large\"] = df[\"SMALL BAGS\"] * df[\"LARGE BAGS\"]\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"small_large\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"small_large\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034b1d0",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Apply !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7bb24",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Applies a function along an axis of the DataFrame.\n",
    "[Read the docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a080d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "When I do an apply on a column, even though I use a lambda, I don't put axis because in the case below, what I'm doing is modifying a column, I use lambda to tell the apply that the first argument is a string that comes from outside and the second argument is the dataframe's own record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82722528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"new_total_bags\"] = #int(itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c544d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_int (x):\n",
    "    if x < 1000:\n",
    "        return int(x)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e3d23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"new_total_bags\"] = df[\"TOTAL BAGS\"].apply(into_int) #the value is implicit and corresponds \n",
    "#to the row of the column I'm calling: TOTAL BAGS\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db5bbe",
   "metadata": {},
   "source": [
    "The same way map receives a function and something it iteraves over\n",
    "A DF is composed of numpy.arrays. So it's an iterable\n",
    "\n",
    "\n",
    "#### Passing a map or an apply\n",
    "- map -> function, iterable\n",
    "- apply -> function, iterable\n",
    "\n",
    "\n",
    "#### Receive:\n",
    "\n",
    "- apply & user-defined function -> apply(function) \"x\", a value\n",
    "- apply & lambda -> lambda row: row[\"column\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e671881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"brand_new_column\"] = df.apply(lambda row: row[\"REGION\"]  if row[\"YEAR\"] > 2015 else \"Something\", axis = 1)\n",
    "df.sample()\n",
    "\n",
    "\n",
    "# Here lambda receives the whole row (a Seabsries)\n",
    "# Series an element for every column\n",
    "# Because the whole row, I can access the value of that cell through the label row[\"LABEL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7616f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startswithletter (letter, x):\n",
    "    if x.startswith(letter):\n",
    "        return x\n",
    "    else:\n",
    "        return f\"It doesn't start with {letter}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q: Can you pass a function to a lambda? \n",
    "\n",
    "df[\"yetanotherone\"] = df.region.apply(lambda cell: (startswith(\"L\", cell)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"yetanotherone\"] = df[\"REGION\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-intro",
   "metadata": {},
   "source": [
    "## Df .loc & .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510cb04",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Select rows and columns in Pandas by position with iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d0d9b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "loc syntax with multiple conditions\n",
    "```python\n",
    "df.loc[(df[\"column\"] condition) & (df[\"column\"] condition)]\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b495bd",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The iloc method is used on DataFrames to select elements based on their location. Its syntax is data.iloc[<filas>, <columnas>], where <filas> and <columnas> are the position of the rows and columns that you want to select in the order that they appear in the object. A familiar notation for Matlab users. In a DataFrame, each of the rows has a number that goes from 0 to the total number of rows minus one. Being iloc the method that allows selecting the data based on these numbers. The same applies to columns.\n",
    "\n",
    "In iloc there are two arguments rows and columns. In case the second is omitted, all columns in the row will be selected. So to select different rows can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e2963",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Select rows and columns in Pandas based on labels with loc\n",
    "The loc method can be used in two different ways: select rows or columns based on a label, or select rows or columns based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91902d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1361] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5:10, 3:7] #Integersb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992e0aa",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Based on label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ab4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"REGION\"]==\"California\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbace39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading\n",
    "df_index_date = pd.read_csv(\"../datasets/avocado_kaggle.csv\")\n",
    "\n",
    "#Setting the index as the date\n",
    "df_index_date = df.set_index(\"date\")\n",
    "df_index_date.head()\n",
    "\n",
    "# Accessing the row bu it's label\n",
    "df_index_date.loc[\"2015-12-06\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71547174",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Order a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"TOTAL VOLUME\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec024b5f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Same operation, but give me only concrete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bde61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = df.loc[(df[\"YEAR\"] > 2016) & (df[\"REGION\"] != \"Albany\")]\n",
    "new_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_column_based_on_date\"] = df.apply(lambda x: f\"{x['YEAR']} after 2015\" if x[\"TOTAL VOLUME\"] > 1000 else f\"Before {x['YEAR']}\", axis=1)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da7dac",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Look for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff205c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = sns.load_dataset(\"titanic\")\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b87f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799f8c3",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### It is null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a423698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of NaN in df in all columns\n",
    "\n",
    "total_nan_in_df = df_titanic.isna().sum().sum()\n",
    "total_nan_in_df #just sum() the sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37071b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b06841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb33c3",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Is NOT null?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-private",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f613b0e2",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Sum the null values ​​of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-finder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4d38c63",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### delete null values\n",
    "There are several ways to do this, we take into account the \"how\" parameter and of course [the docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cacf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q: What if I want to target only one column for NaN\n",
    "#You can select a subset by passind subset = []\n",
    "#Read the docs: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-nickname",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test1 = df_titanic.dropna(subset=[\"age\"])\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbac5b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "REMEMBER THAT INPLACE TRUE IS FOR THE METHOD TO ACTION ON THE DF, IF NOT, I HAVE TO SAVE IT IN A NEW VARIABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f12eb",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "With \"any\" (parameter that comes by default so be careful not to put anything) all the records in which there is a NaN in any column are deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97481f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = df_titanic.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a782576",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### How to fill in the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718df0e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "How about a little [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic[\"deck\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic[\"age\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic[\"age\"].fillna(df_titanic[\"age\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic[\"age\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f74ea1",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "##### CATEGORIES IN DATAFRAME: DOCUMENTATION\n",
    "https://runebook.dev/en/docs/pandas/user_guide/categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b7fef",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## We delete the duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202728a8",
   "metadata": {},
   "source": [
    "[Read the docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d014a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to remove duplicated values on ONE column\n",
    "df_titanic.drop_duplicates(subset = [\"id\"]inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I want to remove BOTH entries for the same ID if it's repeated: \n",
    "# It won't work, as this is an example and ID doesn't exist as a column\n",
    "\n",
    "df_titanic.drop_duplicates(subset = [\"id\"], keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab22120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43326c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df[\"REGION\"].unique()) == list(df[\"REGION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2aaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to check for two fields no to hold the same value in different rows\n",
    "# df.isduplicated(subset=[\"column1\", \"column2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b9ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a94a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=[\"REGION\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afe063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5049b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"REGION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can I check for duplicated values inside of given column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\n",
    "    {\"name\":\"albert\",\n",
    "    \"age\":30},\n",
    "    \n",
    "    {\"name\":\"albert\",\n",
    "    \"age\":22},\n",
    "    \n",
    "    {\"name\":\"clara\",\n",
    "    \"age\":20},\n",
    "    \n",
    "    {\"name\":\"albert\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_check = pd.DataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_check.duplicated(subset=[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51e74f4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Data aggregation\n",
    "### GroupBy\n",
    "Pandas GroupBy is a powerful and versatile function in Python. It allows us to split your data into separate groups to perform calculations for better analysis.\n",
    "A DataFrame can be grouped on its rows (axis=0) or on its columns (axis=1). Once this is done, a function is applied to each group, producing a new value. Finally, the results of all those function applications are combined into a result object. The shape of the resulting object will usually depend on what is done with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-malpractice",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-japanese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0acc8190",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Suppose we want to calculate the mean of column data1 using the labels of key1. There are several ways to do it. One is to access data1 and call groupby with the column (a String) in key1.\n",
    "The data (a Series) has been aggregated based on the group key, producing a new String that is now indexed by the unique values ​​of the key1 column. The resulting index has the name 'key1' because the DataFrame column `df['key1']` did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992fda4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### You may ask, what if I want to group by more columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-radio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d23b8f4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Another way to groupby with agg syntax\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html\n",
    "\n",
    "- mean\n",
    "- sum\n",
    "-count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3eb62",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Union of Dataframes\n",
    "- https://realpython.com/pandas-merge-join-and-concat/\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "\n",
    "\n",
    "### Concat\n",
    "We join dataframes along axis 0 one below the other. Align columns by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac484cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "weekly-klein",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd9a95",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "[Merge()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) is most useful when you want to merge rows that share data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-collaboration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c40f19",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# When the data does not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-cross",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e952e34",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Join\n",
    "The join, unlike the merge, will join the dataframes and where there are no records in the \"index\" it will put NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-combine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3a34a5",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-milton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f340806",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Pandas usual methods\n",
    "```python\n",
    "df.head() # prints the head, default 5 rows\n",
    "df.tail() # set the tail, default 5 rows\n",
    "df.describe() # statistical description\n",
    "df.info() # df information\n",
    "df.info(memory_usage='deep')\n",
    "df.columns # show column\n",
    "df.index # show index\n",
    "df.dtypes # show column data types\n",
    "df.plot() # make a plot\n",
    "df.hist() # make a histogram\n",
    "df.col.value_counts() # counts the unique values ​​of a column\n",
    "df.col.unique() # returns unique values ​​from a column\n",
    "df.copy() # copies the df\n",
    "df.drop() # remove columns or rows (axis=0,1)\n",
    "df.dropna() # remove nulls\n",
    "df.fillna() # fills nulls\n",
    "df.shape # dimensions of the df\n",
    "df._get_numeric_data() # select numeric columns\n",
    "df.rename() # rename columns\n",
    "df.str.replace() # replace columns of strings\n",
    "df.astype(dtype='float32') # change the data type\n",
    "df.iloc[] # locate by index\n",
    "df.loc[] # locate by element\n",
    "df.transpose() # transposes the df\n",
    "df.T\n",
    "df.sample(n, frac) # sample from df\n",
    "df.col.sum() # sum of a column\n",
    "df.col.max() # maximum of a column\n",
    "df.col.min() # minimum of one column\n",
    "df[col] # select column\n",
    "df.col\n",
    "df.isnull() # null values\n",
    "df.isna()\n",
    "df.notna() # not null values\n",
    "df.drop_duplicates() # remove duplicates\n",
    "df.reset_index(inplace=True) # reset the index and overwrite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47efbabe",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Summary\n",
    "It's your turn, what have we learned today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae2c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stylish-jefferson",
   "metadata": {},
   "source": [
    "## Further materials\n",
    "\n",
    "* [Read the docs!](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* [Cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "* [Exercises to practice](https://github.com/guipsamora/pandas_exercises)\n",
    "* [More on merge, concat, and join](https://realpython.com/pandas-merge-join-and-concat/#pandas-join-combining-data-on-a-column-or-index). And [even more!](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
